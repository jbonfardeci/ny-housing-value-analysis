{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York Housing Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis by John Bonfardeci\n",
    "jbonfardeci@definitivelogic.com\n",
    "2018-12-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(lattice) # plotting lib required for car package\n",
    "library(car) # includes vif(), scatterplotMatrix()\n",
    "library(ggplot2) # plotting\n",
    "#library(MASS)\n",
    "library(dplyr) # common utilities for filtering\n",
    "library(glmnet) # LASSO\n",
    "library(caret) # includes methods for LASSO selection, trainControl CV k-fold\n",
    "\n",
    "#install.packages('dummies')\n",
    "library(dummies) # for converting categorical variables into indicator/dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "**What variables in the data set predict the Full Market Value of a house?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample: Housing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import housing data set into dataframe instance.\n",
    "df = read.csv(\"housing.csv\")\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore: Univariate Analysis\n",
    "* Look for skewness in histograms\n",
    "    * A large empty space to the left is \"skewed right.\"\n",
    "    * A large empty space to the right is \"skewed left.\"\n",
    "    * If skewed, will log-transforming the variable make the distribution more normal (bell-shapped)?\n",
    "* Look for outliers in the box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display quantiles of variables in the housing data set.\n",
    "summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boro <- df$Boro\n",
    "\n",
    "# counts\n",
    "ggplot(data.frame(boro), aes(x=boro)) +\n",
    "  geom_bar() + labs(title=\"Count of Boro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood <- df$Neighborhood\n",
    "ggplot(data.frame(neighborhood), aes(x=neighborhood)) +\n",
    "  geom_bar() + labs(title=\"Count of Neighborhood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_class <- df$BuildingClassification\n",
    "ggplot(data.frame(building_class), aes(x=building_class)) +\n",
    "  geom_bar() + labs(title=\"Count of Building Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2, 2))\n",
    "\n",
    "hist(df$TotalUnits, main = \"Total Units\", xlab = \"Total Units\")\n",
    "\n",
    "boxplot(df$TotalUnits, main = \"Total Units\",\n",
    "    xlab = \"Units\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)\n",
    "\n",
    "df$logTotalUnits <- log(df$TotalUnits)\n",
    "\n",
    "hist(df$logTotalUnits, main = \"Log(Total Units)\", xlab = \"Log(Total Units)\")\n",
    "\n",
    "boxplot(df$logTotalUnits, main = \"Log(Total Units)\",\n",
    "    xlab = \"Log(Units)\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2, 2))\n",
    "\n",
    "hist(df$GrossSqFt, main = \"Gross Sq. Ft.\")\n",
    "\n",
    "boxplot(df$GrossSqFt, main = \"Gross Sq. Ft.\",\n",
    "    xlab = \"Sq. Ft.\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)\n",
    "\n",
    "df$logGrossSqFt <- log(df$GrossSqFt)\n",
    "\n",
    "hist(df$logGrossSqFt, main = \"Log(Gross Sq. Ft.)\")\n",
    "\n",
    "boxplot(df$logGrossSqFt, main = \"Log(Gross Sq. Ft.)\",\n",
    "    xlab = \"Log(Sq. Ft.)\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2, 2))\n",
    "\n",
    "hist(df$EstimatedGrossIncome, main = \"Estimated Gross Income\")\n",
    "\n",
    "boxplot(df$EstimatedGrossIncome, main = \"Estimated Gross Income\",\n",
    "    xlab = \"Estimated Gross Income\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)\n",
    "\n",
    "df$logEstimatedGrossIncome <- log(df$EstimatedGrossIncome)\n",
    "\n",
    "hist(df$logEstimatedGrossIncome, main = \"Log(Estimated Gross Income)\")\n",
    "\n",
    "boxplot(df$logEstimatedGrossIncome, main = \"Log(Estimated Gross Income)\",\n",
    "    xlab = \"Log(Estimated Gross Income)\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2, 2))\n",
    "\n",
    "hist(df$GrossIncomePerSqFt, main = \"Gross Income/Sq. Ft.\")\n",
    "\n",
    "boxplot(df$GrossIncomePerSqFt, main = \"Gross Income/Sq. Ft.\",\n",
    "    xlab = \"Gross Income/Sq. Ft.\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)\n",
    "\n",
    "df$logGrossIncomePerSqFt <- log(df$GrossIncomePerSqFt)\n",
    "\n",
    "hist(df$logGrossIncomePerSqFt, main = \"Log(Gross Income/Sq. Ft.)\")\n",
    "\n",
    "boxplot(df$logGrossIncomePerSqFt, main = \"Log(Gross Income/Sq. Ft.)\",\n",
    "    xlab = \"Log(Gross Income/Sq. Ft.)\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2, 2))\n",
    "\n",
    "hist(df$EstimatedExpense, main = \"Estimated Expense\")\n",
    "\n",
    "boxplot(df$EstimatedExpense, main = \"Estimated Expense\",\n",
    "    xlab = \"Estimated Expense\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)\n",
    "\n",
    "df$logEstimatedExpense <- log(df$EstimatedExpense)\n",
    "\n",
    "hist(df$logEstimatedExpense, main = \"Log(Estimated Expense)\")\n",
    "\n",
    "boxplot(df$logEstimatedExpense, main = \"Log(Estimated Expense)\",\n",
    "    xlab = \"Log(Estimated Expense)\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2, 2))\n",
    "\n",
    "hist(df$ExpensePerSqFt, main = \"Expense/Sq. Ft.\")\n",
    "\n",
    "boxplot(df$ExpensePerSqFt, main = \"Expense/Sq. Ft.\",\n",
    "    xlab = \"Expense/Sq. Ft.\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)\n",
    "\n",
    "df$logExpensePerSqFt <- log(df$ExpensePerSqFt)\n",
    "\n",
    "hist(df$logExpensePerSqFt, main = \"Log(Expense/Sq. Ft.)\")\n",
    "\n",
    "boxplot(df$logExpensePerSqFt, main = \"Log(Expense/Sq. Ft.)\",\n",
    "    xlab = \"Log(Expense/Sq. Ft.)\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2, 2))\n",
    "\n",
    "hist(df$NetOperatingIncome, main = \"Net Operating Income\")\n",
    "\n",
    "boxplot(df$NetOperatingIncome, main = \"Net Operating Income\",\n",
    "    xlab = \"Net Operating Income\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)\n",
    "\n",
    "df$logNetOperatingIncome <- log(df$NetOperatingIncome)\n",
    "\n",
    "hist(df$logNetOperatingIncome, main = \"Log(Net Operating Income)\")\n",
    "\n",
    "boxplot(df$logNetOperatingIncome, main = \"Log(Net Operating Income)\",\n",
    "    xlab = \"Log(Net Operating Income)\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2, 2))\n",
    "\n",
    "hist(df$FullMarketValue, main = \"Full Market Value\")\n",
    "\n",
    "boxplot(df$FullMarketValue, main = \"Full Market Value\",\n",
    "    xlab = \"Full Market Value\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)\n",
    "\n",
    "df$logFullMarketValue <- log(df$FullMarketValue)\n",
    "\n",
    "hist(df$logFullMarketValue, main = \"Log(Full Market Value)\")\n",
    "\n",
    "boxplot(df$logFullMarketValue, main = \"Log(Full Market Value)\",\n",
    "    xlab = \"Log(Full Market Value)\",\n",
    "    col = \"orange\",\n",
    "    border = \"brown\",\n",
    "    horizontal = TRUE,\n",
    "    notch = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numerical variables.\n",
    "numerical <- subset(df, select = -c(ID, Neighborhood, BuildingClassification, Boro, YearBuilt, \n",
    "                                    logTotalUnits, logGrossSqFt, logEstimatedGrossIncome, logGrossIncomePerSqFt,\n",
    "                                    logEstimatedExpense, logExpensePerSqFt, logNetOperatingIncome, logFullMarketValue,\n",
    "                                    logGrossIncomePerSqFt, GrossIncomePerSqFt, logExpensePerSqFt, ExpensePerSqFt, MarketValuePerSqFt)) \n",
    "\n",
    "# Display a scatter plot matrix to identify linear relationships between variables.\n",
    "scatterplotMatrix(numerical, main=\"Scatter Plot Matrix\") \n",
    "#spread=FALSE, smoother.args=list(lty=2), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Correlation Matrix\n",
    "cor(numerical)\n",
    "# Positive numbers indicate a linear relationship between two variables.\n",
    "# Numbers ~0 indicate little to no relationship.\n",
    "# Numbers < 0 indicate inverse correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into 70% training and 30% validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 70% of sample\n",
    "sample_size <- floor(0.7 * nrow(df))\n",
    "\n",
    "# set seed to make partitions reproducible.\n",
    "set.seed(42)\n",
    "train_ind <- sample( seq_len(nrow(df)), size = sample_size)\n",
    "\n",
    "# Get training set\n",
    "train_data <- df[train_ind, ]\n",
    "\n",
    "# Get validation set\n",
    "validation <- df[-train_ind, ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression model with lm()\n",
    "fit <- lm(FullMarketValue ~ EstimatedGrossIncome, data = train_data)\n",
    "plot(train_data$EstimatedGrossIncome, train_data$FullMarketValue, xlab = \"Estimated Gross Income\", ylab = \"Full Market Value\", \n",
    "     main = \"Full Market Value Model\")\n",
    "abline(fit, col = \"red\", lty=1, lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(fit)\n",
    "bic = BIC(fit)\n",
    "paste(\"BIC\", \":\", BIC(fit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asjusted R-squared is .97 meaning the model accounts for 97% of the variance in EstimatedGrossIncome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot of standardized residuals by the fitted values. If non-constant variance, \n",
    "# increasing variance from left to right, the model is not valid.\n",
    "par(mfrow=c(2,2))\n",
    "plot(fit, pch = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the model valid?\n",
    "* **Linearity** - (Top Left)\n",
    "    * If Y is linearly related to X, there should be no relationship between the residuals and th efitted values. \n",
    "    * The scatter plot should show be random noise.\n",
    "    * Since there's increasing variance from left to right, the linearity assumption is violated.\n",
    "\n",
    "* **Normality** - (Top Right)\n",
    "    * If Y is normally distrubuted, then the residual values should be normally distributed with a mean of 0.\n",
    "    * Q-Q plot is a probability plot of the std. residuals against the values that would be expected under normality.\n",
    "    * The points do not fall on this line, so the normality assumption is violated.\n",
    "\n",
    "* **Homoscedasticity** (Bottom Left)\n",
    "    * A plot of the std. residuals against the fitted values should show constant variance (random noise) about a horizontal line.\n",
    "    * Assumption of Homoscedasticity is violated.\n",
    "    \n",
    "* **Outliers** - Std. Residuals against Cook's Distance\n",
    "    * Observations with Std. Residual < -3 or > 3 have a *high leverage* value. They're outliers.\n",
    "    * Observations that have a Cook's Distance value > 1 are overly influential.\n",
    "    \n",
    "**The model is INVALID!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to we fix an invalid model?\n",
    "We know from the histograms that both the response variable and the predictor are not normally distributed - they're both skewed. We know that log-transforming can make a variable normally distributed, so we try log-transforming the response variable and the predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform the X\n",
    "par(mfrow=c(2,1))\n",
    "hist(df$logEstimatedGrossIncome, main = \"Log(Estimated Gross Income)\")\n",
    "boxplot(df$logEstimatedGrossIncome, main = \"Log(Estimated Gross Income)\", horizontal = TRUE)\n",
    "# The histogram displayed shows a more normal distribution than the non-log-transformed version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform the Y\n",
    "par(mfrow=c(2,1))\n",
    "hist(log(df$logFullMarketValue), main = \"Log(Full Market Value)\")\n",
    "boxplot(log(df$logFullMarketValue), main = \"Log(Full Market Value)\", horizontal = TRUE)\n",
    "# The histogram displayed shows a more normal distribution than the non-log-transformed version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Re-fit the model with the log-transformed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a new model with the log-transformed versions.\n",
    "log_fit <- lm(logFullMarketValue ~ logEstimatedGrossIncome, data = train_data)\n",
    "plot(train_data$logEstimatedGrossIncome, train_data$logFullMarketValue, xlab = \"Log(Estimated Gross Income)\", ylab = \"Log(Full Market Value)\")\n",
    "abline(log_fit, col = \"red\", lty=1, lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the elliptical symmetry about the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(log_fit)\n",
    "bic2 <- BIC(log_fit)\n",
    "paste(\"BIC 1\", \":\", bic)\n",
    "paste(\"BIC 2\", \":\", bic2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Fit\n",
    "* Adjusted R-squared is 0.98 - `logEstimatedGrossIncome` accounts for 98% of the variance in `logFullMarketValue`.\n",
    "* BIC (Bayesian Information Criterion) decreased from 60847 to -866.7 Lower is better.\n",
    "* The p-value for the y-intercept is significant (p-value < 0.05)\n",
    "* Predictor `logEstimatedGrossIncome` is significant (p-value < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we have constant variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for constant variance\n",
    "ncvTest(log_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value from `ncvTest()` is **not significant** (> 0.05), suggesting we've met the assumuption of constant variance.\n",
    "With the exception of outliers, it would appear we've **met the assumption of constant variance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot of residuals by the fitted values. Do we have constant variance?\n",
    "par(mfrow=c(2,2))\n",
    "plot(log_fit, pch = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(log_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula\n",
    "Based on the `summary()` output above, we have the Y-intercept (Beta 0) and coefficient of Beta 1. \n",
    "\n",
    "Our formula is:\n",
    "\n",
    "`Y-hat = 0.700055 + 1.056609(X1), where Y-hat = Log(FullMarketValue), X1 = Log(EstimatedGrossIncome)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretaion of the Model\n",
    "\n",
    "When log-transforming a dependent variable and/or predictor, our interpretation of the model will change.\n",
    "Normally an in/decrease in one unit of X corresponds to an in/decrease in one unit of Y.\n",
    "When dealing with log-transforms for both Y and X, the interpretation is:\n",
    "\n",
    "**A 1% increase in Log(EstimatedGrossIncome) is predicted to increase Log(FullMarketValue) by 1.057%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlierTest(log_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leverage Points\n",
    "* A *leverage point* is a point whose x-value is distant from the other x-values.\n",
    "* Data points which exercise considerable influence on the fitted model.\n",
    "* Not all leverage points are bad leverage points.\n",
    "* All bad leverage points are outliers but not all outliers are bad leverage points.\n",
    "* We'll determine if a leverage point is bad using Cook's Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized Residual (aka, Studentized Residual)\n",
    "* a residual divided by it's standard deviation.\n",
    "* As a rule, a studentized residual < -3 or > 3 is a bad leverage point.\n",
    "* In very large data sets, a more appropriate cuttoff is < -4 or > 4, or even < -5 or > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get studentized residuals < -3 or > 3\n",
    "stud_resid <- rstandard(log_fit)\n",
    "\n",
    "# Show rows where Std. Resid. < -3 or > 3\n",
    "train_data$StdResid <- stud_resid\n",
    "r <- filter(train_data, (train_data$StdResid < -3 | train_data$StdResid > 3))\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cook's Distance\n",
    "* R. Dennis Cook. University of Minnesota. 1977. (https://en.wikipedia.org/wiki/R._Dennis_Cook)\n",
    "* Cook's Distance is a composite measure of outlyingness and leverage.\n",
    "* Rule of thumb (They're more like guidelines.):\n",
    "    * Cook's Distance > 1 - investigate. Adding a dummy variable to these cases can change regression estimates.\n",
    "    * Cases with Cook's Distance > 0.5 should also be investigated.\n",
    "    * Also look for gaps om the values of Cook's distance and not just whether values exceed the suggested cuttoff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Cook's Distance points where > 1\n",
    "getCooksD <- function(fit){\n",
    "    stud_resid <- rstandard(fit)\n",
    "    cooks_dist <- cooks.distance(fit)\n",
    "    influential_points <- cooks_dist[cooks_dist >= 1] # Filter on points > 1 with a list comprehension.\n",
    "    influential_points # Display influential points\n",
    "    if( length(influential_points) == 0){\n",
    "        print(\"There are no points with a Cook's D > 1.\")\n",
    "    }\n",
    "\n",
    "    plot(x = cooks_dist, y = stud_resid, main=\"Std. Residuals by Cook's D\", xlab=\"Cook's D\", ylab = \"Studentized Residuals\")\n",
    "}\n",
    "\n",
    "getCooksD(log_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though there are observations with studentized residuals less than -3 and greater than 3, we do not need to worry that they're bad leverage points since none of the Cook's Distance values exceed 1. However those with a Cook's D > 0.5 should be investigated. Results of `outlierTest()` in this case should not be cause for concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we handle bad leverage points?\n",
    "Leverage points need to be investigated but not removed from a model. Doing so can cause us to lose important observations.\n",
    "\n",
    "To negate the influence of a a bad leverage point and improve the model's predictive accuracy, we add what's called a \"dummy variable\" or \"indicator variable.\" This variable has a value of \"1\" if it's a bad leverage point, and a \"0\" otherwise. Dummy variables will cause the beta estimates in the equation to change. This means if there's a bad leverage point in the training set, it won't change the way the model predicts new observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificially set a bad leverage point for this example.\n",
    "train_data$logFullMarketValue[train_data$ID == 2569 ] <- 25\n",
    "\n",
    "log_fit2 <- lm(logFullMarketValue ~ logEstimatedGrossIncome, data = train_data)\n",
    "plot(train_data$logEstimatedGrossIncome, train_data$logFullMarketValue, xlab = \"Log(Estimated Gross Income)\", ylab = \"Log(Full Market Value)\")\n",
    "abline(log_fit2, col = \"red\", lty=1, lwd=2)\n",
    "\n",
    "summary(log_fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a bad leverage point.\n",
    "getCooksD(log_fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add a dummy variable = 1 if Cook's D >= 1.\n",
    "train_data$CooksD <- cooks.distance(log_fit2)\n",
    "\n",
    "# Create a Dummy colunm with default value 0.\n",
    "train_data$Overpriced <- rep(0, nrow(train_data))\n",
    "\n",
    "# Set the dummy == 1 on the bad leverage point.\n",
    "train_data$Overpriced[train_data$ID == 2569 ] <- 1\n",
    "\n",
    "head(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After adding the dummy variable, we see the regression line is no longer affected.\n",
    "log_fit3 <- lm(logFullMarketValue ~ logEstimatedGrossIncome + Overpriced, data = train_data)\n",
    "train_data$Yhat <- predict(log_fit3, train_data)\n",
    "\n",
    "plot(train_data$Yhat, train_data$logFullMarketValue, xlab = \"Predicted\", ylab = \"Actual\")\n",
    "abline(lm(logFullMarketValue ~ Yhat, data = train_data), col = \"red\", lty=1, lwd=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients after adding the dummy variable are not much different than the previous fit.\n",
    "# Take note of the small differences in the Intercepts and estimated for `logEstimatedGrossIncome`.\n",
    "print(\"Fit Without Bad Leverage Point\")\n",
    "summary(log_fit2)\n",
    "\n",
    "print(\"Fit With Bad Leverage Point\")\n",
    "summary(log_fit3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Validation Dataset\n",
    "Our formula is:\n",
    "`y-hat <- 0.689401 + (1.057403 * x1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictMarketValue <- function(x1){\n",
    "  return (0.689401 + (1.057403 * x1))\n",
    "}\n",
    "\n",
    "# Create a new column in validation called `Yhat` to store predictions from our formula.\n",
    "validation$Yhat <- rep(0, nrow(validation))\n",
    "\n",
    "# Predict Full Market Value each observation.\n",
    "for(i in 1:nrow(validation)){\n",
    "  egi <- validation$logEstimatedGrossIncome[i]\n",
    "  validation$Yhat[i] <- predictMarketValue(egi)\n",
    "}\n",
    "\n",
    "# Show top 10 results.\n",
    "head(validation)\n",
    "\n",
    "#predictions <- predict(log_fit3, validation)\n",
    "\n",
    "#validation$Yhat <- predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(validation$Yhat, validation$logFullMarketValue, xlab = \"Predicted\", ylab = \"Actual\")\n",
    "abline(lm(logFullMarketValue ~ Yhat, data = validation), col = \"red\", lty=1, lwd=2)\n",
    "\n",
    "# Export the validation set.\n",
    "#write.csv(validation, \"validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Categorical Variables to Indicator Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add New Variable for Age\n",
    "Imputation of Missing (NA) Values\n",
    "* There are NA values in the YearBuilt column.\n",
    "* Determine if percentage of YearBuilt == NA is acceptable to replace with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows <- nrow(df)\n",
    "\n",
    "# Get mean of YearBuilt excluding NA values.\n",
    "missing_year_count <- nrow( filter(df, is.na(YearBuilt)) )\n",
    "perc_missing <- missing_year_count / nrows * 100\n",
    "\n",
    "print(paste(\"Missing\", round(perc_missing, 2), \"% of YearBuilt values.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for YearBuilt\n",
    "mean_year <- floor( mean(df$YearBuilt[!is.na(df$YearBuilt)]) )\n",
    "current_year <- 2018\n",
    "\n",
    "for(i in 1:nrow(df)){\n",
    "    yr <- df$YearBuilt[i]\n",
    "    age <- 0\n",
    "    \n",
    "    if(is.na(yr)){\n",
    "        age <- current_year - mean_year\n",
    "    } else {\n",
    "        age <- current_year - yr\n",
    "    }\n",
    "    \n",
    "    df$Age[i] <- age\n",
    "}\n",
    "\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Categorical Variables to Indicator Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset <- subset(df, select = -c(TotalUnits, YearBuilt, GrossSqFt, EstimatedGrossIncome, \n",
    "                                    GrossIncomePerSqFt, EstimatedExpense, ExpensePerSqFt, \n",
    "                                    NetOperatingIncome, FullMarketValue, MarketValuePerSqFt, \n",
    "                                    logGrossIncomePerSqFt, \n",
    "                                    logExpensePerSqFt, Neighborhood)) \n",
    "\n",
    "head(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 <- dummy.data.frame(df_subset, names=c(\"Boro\", \"BuildingClassification\"), sep=\"_\")\n",
    "names(df2) <- make.names(names(df2)) # remove special characters from column names\n",
    "head(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training set\n",
    "train_data <- df2[train_ind, ]\n",
    "#write.csv(train_data, \"train.csv\")\n",
    "\n",
    "# Get validation set\n",
    "validation2 <- df2[-train_ind, ]\n",
    "#write.csv(validation2, \"validation.csv\")\n",
    "\n",
    "train_data <- subset(train_data, select = -c(ID, logNetOperatingIncome))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection with LASSO\n",
    "* Least Absolute Shrinkage & Selection Operator\n",
    "* Reg. Analys that performs feature selection\n",
    "* Makes the model simpler and more interpretable\n",
    "* Shrinks regression coefficients, with some shrunk to zero. Zero coefficients are removed (feature selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO\n",
    "lasso <- train(logFullMarketValue ~ .,\n",
    "               data = train_data,\n",
    "               tuneGrid = expand.grid(alpha=1, lambda = seq(0.0001, 0.2, length = 5)),\n",
    "               method = \"glmnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importance\n",
    "Shown in order of importance. Those equal to zero are not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Importance plot\n",
    "plot(varImp(lasso, scale=F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 or less is not important.\n",
    "varImp(lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run linrar regression with the variables LASSO selected.\n",
    "# Use variables that LASSO selected\n",
    "lm2 <- train(logFullMarketValue ~ logEstimatedGrossIncome  + \n",
    "    logEstimatedExpense +\n",
    "    Boro_Staten.Island +\n",
    "    logGrossSqFt + \n",
    "    Boro_Bronx +\n",
    "    BuildingClassification_RR.CONDOMINIUM + \n",
    "    Boro_Queens,\n",
    "    data = train_data, \n",
    "    method = \"lm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(lm2$finalModel)\n",
    "# All variables should have a p-value < 0.05 and are significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Inflation Factors (VIFs)\n",
    "* Measures multicollinearity - variables that to highly related.\n",
    "* Variables with a VIF > 10 will cause a model to be unstable. \n",
    "* Small changes in variable values will cause wild shifts in the model.\n",
    "* Goal: remove or combine variables with VIF > 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif(lm2$finalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove variables with high multicollinearity.\n",
    "# Re-fit linear regression model.\n",
    "lm3 <- train(logFullMarketValue ~ logEstimatedGrossIncome +\n",
    "    Boro_Staten.Island +\n",
    "    Boro_Bronx +\n",
    "    BuildingClassification_RR.CONDOMINIUM + \n",
    "    Boro_Queens,\n",
    "    data = train_data, \n",
    "    method = \"lm\")\n",
    "\n",
    "vif(lm3$finalModel)\n",
    "summary(lm3$finalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have a valid model?\n",
    "par(mfrow=c(2,2))\n",
    "plot(lm3$finalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncvTest(lm3$finalModel)\n",
    "# p-value is not significant. Cosntant variance assumption seems to have been met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we have bad leverage points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCooksD(lm3$finalModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are clear outliers, none are overly influential; none have a Cook's Distance > 1 and removing them or adding a dummy variable for these observations will not significant change the estimated coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Linear Regression Model Fit with Significant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted <- predict(lm2, validation2)\n",
    "validation2$Yhat <- predicted\n",
    "\n",
    "plot(validation2$Yhat, validation2$logFullMarketValue, xlab = \"Predicted\", ylab = \"Actual\")\n",
    "abline(lm(logFullMarketValue ~ Yhat, data = validation2), col = \"red\", lty=1, lwd=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
